from modules import logger, exception
from config import AppConfig
from datasets import load_dataset
import os, sys
import pandas as pd

class DataIngestion:
    def __init__(self, dataset_name=None, data_dir=None):
        self.dataset_name = dataset_name
        if data_dir:
            self.data_dir = data_dir
        else:
            self.data_dir = AppConfig.DATA_DIR
        
        self.download_save_dataset()


    def download_save_dataset(self):
        '''
        TWEETSUMM dataset is a dataset focused on summarization of dialogs, 
        which represents the rich domain of Twitter customer care conversations
        https://github.com/guyfe/
        https://huggingface.co/datasets/Andyrasika/TweetSumm-tuned

         TweetSum entry (line) has the following format:
            conversation_id : a unique identifier of the dialog
            tweet_ids_sentence_offset : a list of
            tweet_id : corresponding to Twitter Id in Kaggle Customer Support On Twitter dataset
            sentence offsets : the offsets of the sentences splitting we used.
            annotations : a list of summaries generated by the human annotators - each entry contains :
            extractive : a list of sentences selected from the initial dialog. The sentences are in the format tweet_id, sentence offsets
            abstractive : a list of one or two sentences.
        '''
        try:
            dataset_dir = os.path.join(self.data_dir, self.dataset_name.split('/')[1])
            if not os.path.exists(os.path.join(dataset_dir,'train.csv')):
                logger.logging.info(f"Start downloading the dataset to {self.data_dir }")
                data = load_dataset(self.dataset_name)

                #create the data folder if not exist
                if not os.path.exists(dataset_dir):
                    os.makedirs(dataset_dir)
                
                #save the dataset as csv files
                for division in data.keys():
                    csv_path = os.path.join(dataset_dir, f"{division}.csv")
                    data[division].to_csv(csv_path, index=False)
                    logger.logging.info(f"Data dowloaded to {dataset_dir } successfully!")
            else:
                logger.logging.info(f"Data already exists in {dataset_dir } !, another download is not necessary.")
        except Exception as e:
            raise exception.CustomException(e, sys) from e 

    def load_data(self):
        try: 
            dataset_dir = os.path.join(self.data_dir, self.dataset_name.split('/')[1])
            if not os.path.exists(dataset_dir) and len(os.listdir(dataset_dir))>0:
                self.download_save_dataset()
            else:
                train_df = pd.read_csv(f"{dataset_dir}/train.csv")
                val_df = pd.read_csv(f"{dataset_dir}/test.csv")
                test_df = pd.read_csv(f"{dataset_dir}/test.csv")
                logger.logging.info('Data loaded successfully!')
        except Exception as e:
            raise exception.CustomException(e,sys) from e
        return train_df, val_df, test_df